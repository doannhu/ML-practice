{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating features\n",
    "\n",
    "In this chapter, you will work with a dataset called sales_df, which contains information on advertising campaign expenditure across different media types, and the number of dollars generated in sales for the respective campaign. The dataset has been preloaded for you. Here are the first two rows:\n",
    "\n",
    "     tv        radio      social_media    sales\n",
    "1    13000.0   9237.76    2409.57         46677.90\n",
    "2    41000.0   15886.45   2913.41         150177.83\n",
    "\n",
    "You will use the advertising expenditure as features to predict sales values, initially working with the \"radio\" column. However, before you make any predictions you will need to create the feature and target arrays, reshaping them to the correct format for scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create X from the radio column's values\n",
    "X = sales_df[\"radio\"].values\n",
    "\n",
    "# Create y from the sales column's values\n",
    "y = sales_df[\"sales\"].values\n",
    "\n",
    "print(type(X), type(y))\n",
    "\n",
    "# Reshape X\n",
    "X = X.reshape(-1,1)\n",
    "\n",
    "\n",
    "# Check the shape of the features and targets\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a linear regression model\n",
    "\n",
    "Now you have created your feature and target arrays, you will train a linear regression model on all feature and target values.\n",
    "\n",
    "As the goal is to assess the relationship between the feature and target values there is no need to split the data into training and test sets.\n",
    "\n",
    "X and y have been preloaded for you as follows:\n",
    "\n",
    "y = sales_df[\"sales\"].values\n",
    "X = sales_df[\"radio\"].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X,y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = reg.predict(X)\n",
    "\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing a linear regression model\n",
    "\n",
    "Now you have built your linear regression model and trained it using all available observations, you can visualize how well the model fits the data. This allows you to interpret the relationship between radio advertising expenditure and sales values.\n",
    "\n",
    "The variables X, an array of radio values, y, an array of sales values, and predictions, an array of the model's predicted values for y given X, have all been preloaded for you from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(X, y, color=\"blue\")\n",
    "\n",
    "# Create line plot\n",
    "plt.plot(X, predictions, color=\"red\")\n",
    "plt.xlabel(\"Radio Expenditure ($)\")\n",
    "plt.ylabel(\"Sales ($)\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = a*x + b\n",
    "\n",
    "a & b: model coefficients\n",
    "\n",
    "Loss function: how far each data point to the prediction line. Need to minimize this distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and predict for regression\n",
    "\n",
    "Now you have seen how linear regression works, your task is to create a multiple linear regression model using all of the features in the sales_df dataset, which has been preloaded for you. As a reminder, here are the first two rows:\n",
    "\n",
    "     tv        radio      social_media    sales\n",
    "1    13000.0   9237.76    2409.57         46677.90\n",
    "2    41000.0   15886.45   2913.41         150177.83\n",
    "\n",
    "You will then use this model to predict sales based on the values of the test features.\n",
    "\n",
    "LinearRegression and train_test_split have been preloaded for you from their respective modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y arrays\n",
    "X = sales_df.drop(\"sales\", axis=1).values\n",
    "y = sales_df[\"sales\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression performance\n",
    "\n",
    "Now you have fit a model, reg, using all features from sales_df, and made predictions of sales values, you can evaluate performance using some common regression metrics.\n",
    "\n",
    "The variables X_train, X_test, y_train, y_test, and y_pred, along with the fitted model, reg, all from the last exercise, have been preloaded for you.\n",
    "\n",
    "Your task is to find out how well the features can explain the variance in the target values, along with assessing the model's ability to make predictions on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Compute R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "# Another option: r_squared = reg.score(X_test, y_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "# False means returning the square root of MSE\n",
    "\n",
    "# Print the metrics\n",
    "print(\"R^2: {}\".format(r_squared))\n",
    "print(\"RMSE: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R^2: 0.9990165886162027\n",
    "RMSE: 2942.372219812037\n",
    "# R^2 is from 0 to 1, high R^2 is better. The features explain about 99.90% of result. \n",
    "# \n",
    "# R-squared is a statistical measure of how close the data are to the fitted regression line.\n",
    "# Root MSE in th same units at the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing R-squared on our test set, the R-squared returned is dependent on the way that we split up the data. R-squared computed on it os not presentative of the model's ability to generalize to unseen data.\n",
    "\n",
    "Using cross-validation instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation for R-squared\n",
    "\n",
    "Cross-validation is a vital approach to evaluating a model. It maximizes the amount of data that is available to the model, as the model is not only trained but also tested on all of the available data.\n",
    "\n",
    "In this exercise, you will build a linear regression model, then use 6-fold cross-validation to assess its accuracy for predicting sales using social media advertising expenditure. You will display the individual score for each of the six-folds.\n",
    "\n",
    "The sales_df dataset has been split into y for the target variable, and X for the features, and preloaded for you. LinearRegression has been imported from sklearn.linear_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=6, shuffle= True, random_state= 5)\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Compute 6-fold cross-validation scores\n",
    "cv_scores = cross_val_score(reg, X, y, cv= kf)\n",
    "\n",
    "# Print scores\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.74451678 0.77241887 0.76842114 0.7410406  0.75170022 0.74406484]\n",
    "\n",
    "# 6-fold so the cv_scores has 6 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing cross-validation metrics\n",
    "\n",
    "Now you have performed cross-validation, it's time to analyze the results.\n",
    "\n",
    "You will display the mean, standard deviation, and 95% confidence interval for cv_results, which has been preloaded for you from the previous exercise.\n",
    "\n",
    "numpy has been imported for you as np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean\n",
    "print(np.mean(cv_results))\n",
    "\n",
    "# Print the standard deviation\n",
    "print(np.std(cv_results))\n",
    "\n",
    "# Print the 95% confidence interval\n",
    "print(np.quantile(cv_results, [0.025, 0.975]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7536937416666666\n",
    "0.012305386274436092\n",
    "[0.74141863 0.77191915]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularized regression\n",
    "\n",
    "Ridge regression\n",
    "\n",
    "Ridge penalizes large positive or negative coefficients to avoid overfitting\n",
    "\n",
    "Loss function = OLS loss function + Alpha * sum(a[i]^2) \n",
    "\n",
    "i is from 1 to n\n",
    "\n",
    "Choosing Alpha is similar to pick k in KNN. Alpha is hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "ridge_scores = []\n",
    "for alpha in alphas:\n",
    "  \n",
    "  # Create a Ridge regression model\n",
    "  ridge = Ridge(alpha=alpha)\n",
    "  \n",
    "  # Fit the data\n",
    "  ridge.fit(X_train, y_train)\n",
    "  \n",
    "  # Obtain R-squared\n",
    "  score = ridge.score(X_test, y_test)\n",
    "  ridge_scores.append(score)\n",
    "print(ridge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.9990152104759369, 0.9990152104759373, 0.9990152104759419, 0.9990152104759871, 0.9990152104764387, 0.9990152104809561]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary least squares estimates the parameters in a regression model by minimizing the sum of the squared residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression\n",
    "\n",
    "Loss function = OLS loss function + Alpha * sum(|a[i]|)\n",
    "\n",
    "with i from 1 to n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression for feature importance\n",
    "\n",
    "In the video, you saw how lasso regression can be used to identify important features in a dataset.\n",
    "\n",
    "In this exercise, you will fit a lasso regression model to the sales_df data and plot the model's coefficients.\n",
    "\n",
    "The feature and target variable arrays have been pre-loaded as X and y, along with sales_columns, which contains the dataset's feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Instantiate a lasso regression model\n",
    "lasso = Lasso(alpha=0.3)\n",
    "\n",
    "# Fit the model to the data\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Compute and print the coefficients\n",
    "lasso_coef = lasso.coef_\n",
    "print(lasso_coef)\n",
    "plt.bar(sales_columns, lasso_coef)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result: tv is the largest feature, compares to radio and social_media features"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning Models for Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalance data: When data points of a result are much more than other results.\n",
    "\n",
    "Using other metrics (confusion matrix) to assess the model:\n",
    "\n",
    "Precision = true positives/(true positives + false positives)\n",
    "\n",
    "High precision = low false postitive rate\n",
    "\n",
    "Recall = true positives/(true positives + false negatives)\n",
    "\n",
    "High recall = low false negatives\n",
    "\n",
    "F1_score = 2* (precision*recall)/(precision+recall).F1 score seeks models which perform well across metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding on a primary metric\n",
    "Evaluate performance of classification models: accuracy, precision, recall and F1_score\n",
    "\n",
    "Example:\n",
    "- A model predicting the presence of cancers as the positive class: use recall since the model minimize the number of false negatives\n",
    "- A model predicting the sales of product: use precision to return highest proportion of true positives compares to all predicted positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing a diabetes prediction classifier\n",
    "\n",
    "In this chapter you'll work with the diabetes_df dataset introduced previously.\n",
    "\n",
    "The goal is to predict whether or not each individual is likely to have diabetes based on the features body mass index (BMI) and age (in years). Therefore, it is a binary classification problem. A target value of 0 indicates that the individual does not have diabetes, while a value of 1 indicates that the individual does have diabetes.\n",
    "\n",
    "diabetes_df has been preloaded for you as a pandas DataFrame and split into X_train, X_test, y_train, and y_test. In addition, a KNeighborsClassifier() has been instantiated and assigned to knn.\n",
    "\n",
    "You will fit the model, make predictions on the test set, then produce a confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[116  35]\n",
    " [ 46  34]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.72      0.77      0.74       151\n",
    "           1       0.49      0.42      0.46        80\n",
    "\n",
    "    accuracy                           0.65       231\n",
    "   macro avg       0.60      0.60      0.60       231\n",
    "weighted avg       0.64      0.65      0.64       231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression \n",
    "\n",
    "if the probability p > 0.5, the data is labeled 1\n",
    "\n",
    "if the probability p <0.5, the data is labeled 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a logistic regression model\n",
    "\n",
    "In this exercise, you will build a logistic regression model using all features in the diabetes_df dataset. The model will be used to predict the probability of individuals in the test set having a diabetes diagnosis.\n",
    "\n",
    "The diabetes_df dataset has been split into X_train, X_test, y_train, and y_test, and preloaded for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the probabilities of each individual in the test set having a diabetes diagnosis, storing the array of positive probabilities as y_pred_probs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(logreg.predict_proba(X_test))\n",
    "\n",
    "print(y_pred_probs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Predict_proba result: an array of n_samples * n_classes\n",
    "0(no diabete)1(diabete)\n",
    "[[0.73448969 0.26551031]\n",
    " [0.81663458 0.18336542]\n",
    " [0.87880404 0.12119596]\n",
    " [0.84386435 0.15613565]\n",
    " [0.50388715 0.49611285]\n",
    " [0.55417764 0.44582236]\n",
    " [0.98640765 0.01359235]\n",
    " [0.38353875 0.61646125]\n",
    " [0.44359454 0.55640546]\n",
    " [0.2068813  0.7931187 ]\n",
    " [0.77188668 0.22811332]\n",
    " [0.09960897 0.90039103]\n",
    " [0.61558437 0.38441563]\n",
    " [0.71437835 0.28562165]\n",
    " [0.9304643  0.0695357 ]\n",
    " ....\n",
    "\n",
    " Fist 10 result of positive diabetes probability:\n",
    " [0.26551031 0.18336542 0.12119596 0.15613565 0.49611285 0.44582236\n",
    " 0.01359235 0.61646125 0.55640546 0.7931187 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve\n",
    "\n",
    "Now you have built a logistic regression model for predicting diabetes status, you can plot the ROC curve to visualize how the true positive rate and false positive rate vary as the decision threshold changes.\n",
    "\n",
    "The test labels, y_test, and the predicted probabilities of the test features belonging to the positive class, y_pred_probs, have been preloaded for you, along with matplotlib.pyplot as plt.\n",
    "\n",
    "You will create a ROC curve and then interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Plot tpr against fpr\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Diabetes Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve is above the dotted line, so the model performs better than randomly guessing the class of each observation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

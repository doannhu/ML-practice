{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Models for Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalance data: When data points of a result are much more than other results.\n",
    "\n",
    "Using other metrics (confusion matrix) to assess the model:\n",
    "\n",
    "Precision = true positives/(true positives + false positives)\n",
    "\n",
    "High precision = low false postitive rate\n",
    "\n",
    "Recall = true positives/(true positives + false negatives)\n",
    "\n",
    "High recall = low false negatives\n",
    "\n",
    "F1_score = 2* (precision*recall)/(precision+recall).F1 score seeks models which perform well across metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding on a primary metric\n",
    "Evaluate performance of classification models: accuracy, precision, recall and F1_score\n",
    "\n",
    "Example:\n",
    "- A model predicting the presence of cancers as the positive class: use recall since the model minimize the number of false negatives\n",
    "- A model predicting the sales of product: use precision to return highest proportion of true positives compares to all predicted positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing a diabetes prediction classifier\n",
    "\n",
    "In this chapter you'll work with the diabetes_df dataset introduced previously.\n",
    "\n",
    "The goal is to predict whether or not each individual is likely to have diabetes based on the features body mass index (BMI) and age (in years). Therefore, it is a binary classification problem. A target value of 0 indicates that the individual does not have diabetes, while a value of 1 indicates that the individual does have diabetes.\n",
    "\n",
    "diabetes_df has been preloaded for you as a pandas DataFrame and split into X_train, X_test, y_train, and y_test. In addition, a KNeighborsClassifier() has been instantiated and assigned to knn.\n",
    "\n",
    "You will fit the model, make predictions on the test set, then produce a confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[116  35]\n",
    " [ 46  34]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.72      0.77      0.74       151\n",
    "           1       0.49      0.42      0.46        80\n",
    "\n",
    "    accuracy                           0.65       231\n",
    "   macro avg       0.60      0.60      0.60       231\n",
    "weighted avg       0.64      0.65      0.64       231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression \n",
    "\n",
    "if the probability p > 0.5, the data is labeled 1\n",
    "\n",
    "if the probability p <0.5, the data is labeled 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a logistic regression model\n",
    "\n",
    "In this exercise, you will build a logistic regression model using all features in the diabetes_df dataset. The model will be used to predict the probability of individuals in the test set having a diabetes diagnosis.\n",
    "\n",
    "The diabetes_df dataset has been split into X_train, X_test, y_train, and y_test, and preloaded for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the probabilities of each individual in the test set having a diabetes diagnosis, storing the array of positive probabilities as y_pred_probs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(logreg.predict_proba(X_test))\n",
    "\n",
    "print(y_pred_probs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Predict_proba result: an array of n_samples * n_classes\n",
    "0(no diabete)1(diabete)\n",
    "[[0.73448969 0.26551031]\n",
    " [0.81663458 0.18336542]\n",
    " [0.87880404 0.12119596]\n",
    " [0.84386435 0.15613565]\n",
    " [0.50388715 0.49611285]\n",
    " [0.55417764 0.44582236]\n",
    " [0.98640765 0.01359235]\n",
    " [0.38353875 0.61646125]\n",
    " [0.44359454 0.55640546]\n",
    " [0.2068813  0.7931187 ]\n",
    " [0.77188668 0.22811332]\n",
    " [0.09960897 0.90039103]\n",
    " [0.61558437 0.38441563]\n",
    " [0.71437835 0.28562165]\n",
    " [0.9304643  0.0695357 ]\n",
    " ....\n",
    "\n",
    " Fist 10 result of positive diabetes probability:\n",
    " [0.26551031 0.18336542 0.12119596 0.15613565 0.49611285 0.44582236\n",
    " 0.01359235 0.61646125 0.55640546 0.7931187 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ROC curve\n",
    "\n",
    "Now you have built a logistic regression model for predicting diabetes status, you can plot the ROC curve to visualize how the true positive rate and false positive rate vary as the decision threshold changes.\n",
    "\n",
    "The test labels, y_test, and the predicted probabilities of the test features belonging to the positive class, y_pred_probs, have been preloaded for you, along with matplotlib.pyplot as plt.\n",
    "\n",
    "You will create a ROC curve and then interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Plot tpr against fpr\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Diabetes Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve is above the dotted line, so the model performs better than randomly guessing the class of each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC AUC\n",
    "\n",
    "The ROC curve you plotted in the last exercise looked promising.\n",
    "\n",
    "Now you will compute the area under the ROC curve, along with the other classification metrics you have used previously.\n",
    "\n",
    "The confusion_matrix and classification_report functions have been preloaded for you, along with the logreg model you previously built, plus X_train, X_test, y_train, y_test. Also, the model's predicted test set labels are stored as y_pred, and probabilities of test set observations belonging to the positive class stored as y_pred_probs.\n",
    "\n",
    "A knn model has also been created and the performance metrics printed in the console, so you can compare the roc_auc_score, confusion_matrix, and classification_report between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "0.8002483443708608\n",
    "[[121  30]\n",
    " [ 30  50]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.80      0.80       151\n",
    "           1       0.62      0.62      0.62        80\n",
    "\n",
    "    accuracy                           0.74       231\n",
    "   macro avg       0.71      0.71      0.71       231\n",
    "weighted avg       0.74      0.74      0.74       231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression performs better than the KNN model across all the metrics you calculated? A ROC AUC score of 0.8002 means this model is 60% better than a chance model at correctly predicting labels! scikit-learn makes it easy to produce several classification metrics with only a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with GridSearchCV\n",
    "\n",
    "Now you have seen how to perform grid search hyperparameter tuning, you are going to build a lasso regression model with optimal hyperparameters to predict blood glucose levels using the features in the diabetes_df dataset.\n",
    "\n",
    "X_train, X_test, y_train, and y_test have been preloaded for you. A KFold() object has been created and stored for you as kf, along with a lasso regression model as lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid={\"alpha\": np.arange(0.0001, 1, 10),\n",
    "            \"solver\":[\"sag\", \"lsqr\"]}\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv=kf)\n",
    "\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "print(ridge_cv.best_params_, ridge_cv.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‘lsqr’ uses the dedicated regularized least-squares routine scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative procedure.\n",
    "\n",
    "‘sag’ uses a Stochastic Average Gradient descent, and ‘saga’ uses its improved, unbiased version named SAGA. Both methods also use an iterative procedure, and are often faster than other solvers when both n_samples and n_features are large. Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Import GridSearchCV.\n",
    "    Set up a parameter grid for \"alpha\", using np.linspace() to create 20 evenly spaced values ranging from 0.00001 to 1.\n",
    "    Call GridSearchCV(), passing lasso, the parameter grid, and setting cv equal to kf.\n",
    "    Fit the grid search object to the training data to perform a cross-validated grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\"alpha\": np.linspace(0.00001, 1, num=20)}\n",
    "\n",
    "# Instantiate lasso_cv\n",
    "lasso_cv = GridSearchCV(lasso, param_grid, cv=kf)\n",
    "\n",
    "# Fit to the training data\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "print(\"Tuned lasso paramaters: {}\".format(lasso_cv.best_params_))\n",
    "print(\"Tuned lasso score: {}\".format(lasso_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned lasso paramaters: {'alpha': 1e-05}\n",
    "Tuned lasso score: 0.33078807238121977"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "\n",
    "As you saw, GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space. In this case, you can use RandomizedSearchCV, which tests a fixed number of hyperparameter settings from specified probability distributions.\n",
    "\n",
    "Training and test sets from diabetes_df have been pre-loaded for you as X_train. X_test, y_train, and y_test, where the target is \"diabetes\". A logistic regression model has been created and stored as logreg, as well as a KFold variable stored as kf.\n",
    "\n",
    "You will define a range of hyperparameters and use RandomizedSearchCV, which has been imported from sklearn.model_selection, to look for optimal hyperparameters from these options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Create params, adding \"l1\" and \"l2\" as penalty values, setting C to a range of 50 float values between 0.1 and 1.0, and class_weight to either \"balanced\" or a dictionary containing 0:0.8, 1:0.2.\n",
    "    Create the Randomized Search CV object, passing the model and the parameters, and setting cv equal to kf.\n",
    "    Fit logreg_cv to the training data.\n",
    "    Print the model's best parameters and accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create the parameter space\n",
    "params = {\"penalty\": [\"l1\", \"l2\"],\n",
    "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
    "         \"C\": np.linspace(0.1, 1.0, 50),\n",
    "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "logreg_cv = RandomizedSearchCV(logreg, params, cv=kf)\n",
    "\n",
    "# Fit the data to the model\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "    Tuned Logistic Regression Parameters: {'tol': 0.14294285714285712, 'penalty': 'l2', 'class_weight': 'balanced', 'C': 0.6326530612244898}\n",
    "    Tuned Logistic Regression Best Accuracy Score: 0.7460082633613221"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
